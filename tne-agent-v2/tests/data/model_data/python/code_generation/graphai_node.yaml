agent: nestedAgent
graph:
  version: 0.5
  nodes:
    FuN_kk_xNkwtfNHdVz9rR_codeGeneration:
      agent: codeGenerationTemplateAgent
      params:
        prompt: aaa
      passThrough:
        nodeType: codeGenerationTemplate
        nodeId: FuN_kk_xNkwtfNHdVz9rR_codeGeneration
        nodeTitle: Generate Code
      inputs:
        file: ":file"
        inputs: ":inputs"
        userPrompt: ":userPrompt"
    FuN_kk_xNkwtfNHdVz9rR_llm:
      agent: openAIAgent
      params:
        model: gpt-4o
        max_tokens: 4096
      passThrough:
        nodeType: codeGenerationLlm
        nodeId: FuN_kk_xNkwtfNHdVz9rR_llm
        nodeTitle: Generate Code
      isResult: true
      inputs:
        prompt: ":FuN_kk_xNkwtfNHdVz9rR_codeGeneration.prompt"
        model: ":FuN_kk_xNkwtfNHdVz9rR_codeGeneration.model"
        system: ":FuN_kk_xNkwtfNHdVz9rR_codeGeneration.system"
        temperature: ":FuN_kk_xNkwtfNHdVz9rR_codeGeneration.temperature"
        max_tokens: ":FuN_kk_xNkwtfNHdVz9rR_codeGeneration.max_tokens"
    FuN_kk_xNkwtfNHdVz9rR_python:
      agent: pythonCodeAgent
      params: {}
      passThrough:
        nodeType: pythonCode
        nodeId: FuN_kk_xNkwtfNHdVz9rR_python
        nodeTitle: Generate Code python code
      isResult: true
      inputs:
        code: ":FuN_kk_xNkwtfNHdVz9rR_llm.choices.$0.message.content"
passThrough:
  nodeType: codeGeneration
  nodeId: FuN_kk_xNkwtfNHdVz9rR
  nodeTitle: Generate Code
isResult: true
